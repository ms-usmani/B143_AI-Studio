{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from pyTsetlinMachine.tm import MultiClassTsetlinMachine\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"bank-additional-full.csv\", sep=';')\n",
    "\n",
    "# Display the first few rows of the data to confirm the structure\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Encode categorical variables\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = data.drop(columns=['y_yes'])\n",
    "y = data['y_yes']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'clauses': 200, 'T': 10, 's': 4.5}\n"
     ]
    }
   ],
   "source": [
    "# Genetic Algorithm for feature selection (placeholder function)\n",
    "def genetic_algorithm_feature_selection(X, y):\n",
    "    # Simple feature selection by ranking based on correlation with target\n",
    "    correlations = np.abs([np.corrcoef(X[:, i], y)[0, 1] for i in range(X.shape[1])])\n",
    "    sorted_indices = np.argsort(correlations)[::-1]\n",
    "    selected_features = sorted_indices[:int(0.75 * len(sorted_indices))]  # Select top 75% features\n",
    "    return selected_features\n",
    "\n",
    "# Apply Genetic Algorithm for feature selection\n",
    "selected_features = genetic_algorithm_feature_selection(X_train, y_train)\n",
    "X_train_selected = X_train[:, selected_features]\n",
    "X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "# Binarize the features for Tsetlin Machine\n",
    "X_train_binarized = np.where(X_train_selected > np.median(X_train_selected, axis=0), 1, 0)\n",
    "X_test_binarized = np.where(X_test_selected > np.median(X_test_selected, axis=0), 1, 0)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'clauses': [50, 100, 200],\n",
    "    'T': [10, 15, 20],\n",
    "    's': [3.0, 3.9, 4.5]\n",
    "}\n",
    "\n",
    "\n",
    "def grid_search_tsetlin(X_train, y_train, param_grid):\n",
    "    best_params = None\n",
    "    best_score = 0\n",
    "    for clauses in param_grid['clauses']:\n",
    "        for T in param_grid['T']:\n",
    "            for s in param_grid['s']:\n",
    "                tm = MultiClassTsetlinMachine(clauses, T, s)\n",
    "                tm.fit(X_train, y_train, epochs=10)\n",
    "                y_pred = tm.predict(X_train)\n",
    "                score = accuracy_score(y_train, y_pred)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {'clauses': clauses, 'T': T, 's': s}\n",
    "    return best_params\n",
    "\n",
    "best_params = grid_search_tsetlin(X_train_binarized, y_train, param_grid)\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM with Genetic Algorithm - Accuracy: 0.9017965525613013\n",
      "TM with Genetic Algorithm - Precision: 0.7058823529411765\n",
      "TM with Genetic Algorithm - Recall: 0.23101604278074866\n",
      "TM with Genetic Algorithm - F1 Score: 0.34810636583400484\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize and train the Tsetlin Machine with best parameters\n",
    "tm = MultiClassTsetlinMachine(best_params['clauses'], best_params['T'], best_params['s'])\n",
    "tm.fit(X_train_binarized, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = tm.predict(X_test_binarized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"TM with Genetic Algorithm - Accuracy: {accuracy}\")\n",
    "print(f\"TM with Genetic Algorithm - Precision: {precision}\")\n",
    "print(f\"TM with Genetic Algorithm - Recall: {recall}\")\n",
    "print(f\"TM with Genetic Algorithm - F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.911750424860403, Precision: 0.6444444444444445, Recall: 0.49625668449197863, F1 Score: 0.5607250755287009\n",
      "Logistic Regression - Accuracy: 0.9112648701141054, Precision: 0.6711409395973155, Recall: 0.42780748663101603, F1 Score: 0.5225342913128674\n",
      "SVM - Accuracy: 0.9081087642631707, Precision: 0.6731517509727627, Recall: 0.3700534759358289, F1 Score: 0.4775707384403037\n",
      "Gradient Boosting - Accuracy: 0.920004855547463, Precision: 0.6885245901639344, Recall: 0.5390374331550802, F1 Score: 0.6046790641871626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train and evaluate Random Forest with selected features\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_selected, y_train)\n",
    "y_pred_rf = rf.predict(X_test_selected)\n",
    "\n",
    "# Train and evaluate Logistic Regression with selected features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_selected, y_train)\n",
    "y_pred_lr = lr.predict(X_test_selected)\n",
    "\n",
    "# Train and evaluate SVM with selected features\n",
    "svm = SVC()\n",
    "svm.fit(X_train_selected, y_train)\n",
    "y_pred_svm = svm.predict(X_test_selected)\n",
    "\n",
    "# Train and evaluate Gradient Boosting with selected features\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train_selected, y_train)\n",
    "y_pred_gb = gb.predict(X_test_selected)\n",
    "\n",
    "# Evaluation Metrics\n",
    "models = {'Random Forest': y_pred_rf, 'Logistic Regression': y_pred_lr, 'SVM': y_pred_svm, 'Gradient Boosting': y_pred_gb}\n",
    "\n",
    "for model_name, y_pred in models.items():\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"{model_name} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
